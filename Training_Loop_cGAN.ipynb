{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop\n"
      ],
      "metadata": {
        "id": "cFZlQsW80hcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for current_epoch in range(total_epochs):\n",
        "    # Initialize epoch losses\n",
        "    epoch_generator_loss = 0.0\n",
        "    epoch_discriminator_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Iterate over batches in the training dataloader\n",
        "    for real_images, labels, sketches, _ in tqdm(train_data_loader):\n",
        "        # Move data to device\n",
        "        real_images, labels, sketches = real_images.to(DEVICE), labels.to(DEVICE), sketches.to(DEVICE)\n",
        "\n",
        "        # Forward pass through the generator\n",
        "        generated_images = generator(sketches, labels.to(torch.long)).to(DEVICE)\n",
        "\n",
        "        # Train the discriminator\n",
        "        disc_real_output = discriminator(real_images, labels.to(torch.long)).reshape(-1).to(DEVICE)\n",
        "        disc_fake_output = discriminator(generated_images.detach(), labels.to(torch.long)).reshape(-1)\n",
        "        disc_real_loss = criterion(disc_real_output, torch.ones_like(disc_real_output))\n",
        "        disc_fake_loss = criterion(disc_fake_output, torch.zeros_like(disc_fake_output))\n",
        "        discriminator_loss = (disc_real_loss + disc_fake_loss) / 2\n",
        "\n",
        "        # Backpropagation and optimization for discriminator\n",
        "        discriminator.zero_grad()\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "\n",
        "        # Train the generator\n",
        "        gen_fake_output = discriminator(generated_images, labels.to(torch.long)).reshape(-1)\n",
        "        gen_loss_adversarial = criterion(gen_fake_output, torch.ones_like(gen_fake_output))\n",
        "        gen_loss_reconstruction = L1_LOSS(generated_images, real_images) * 100\n",
        "        generator_loss = gen_loss_adversarial + gen_loss_reconstruction\n",
        "\n",
        "        # Backpropagation and optimization for generator\n",
        "        generator.zero_grad()\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        # Accumulate losses\n",
        "        epoch_generator_loss += generator_loss.item()\n",
        "        epoch_discriminator_loss += discriminator_loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        # Logging and visualization\n",
        "        if current_epoch % display_step == 0 and current_epoch > 0:\n",
        "            # Calculate mean losses for the current step\n",
        "            mean_generator_loss = epoch_generator_loss / num_batches\n",
        "            mean_discriminator_loss = epoch_discriminator_loss / num_batches\n",
        "\n",
        "            # Log losses\n",
        "            wandb.log({\"generator_loss_per_step\": mean_generator_loss, \"discriminator_loss_per_step\": mean_discriminator_loss}, step=current_epoch)\n",
        "\n",
        "            # Plot generated and real images\n",
        "            plot_images_from_tensor(generated_images, name=\"fake_images\")\n",
        "            plot_images_from_tensor(real_images, name=\"real_images\")\n",
        "\n",
        "            # Compute and log Inception Score and FID Score\n",
        "            inception_score_val = inception_score(generated_images.to(\"cpu\"))\n",
        "            fid_score_val = calculate_fid(real_images, generated_images, device='cpu')\n",
        "            wandb.log({\"inception_score\": inception_score_val, \"FID score\": fid_score_val}, step=current_epoch)\n",
        "\n",
        "            # Plot losses over time\n",
        "            step_bins = 20\n",
        "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
        "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins),\n",
        "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Generator Loss\",\n",
        "            )\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins),\n",
        "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Discriminator Loss\",\n",
        "            )\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        elif current_epoch == 0:\n",
        "            print(\"Training has started, let it continue...\")\n",
        "        current_epoch += 1\n",
        "\n",
        "    # Calculate average epoch losses\n",
        "    avg_epoch_generator_loss = epoch_generator_loss / num_batches\n",
        "    avg_epoch_discriminator_loss = epoch_discriminator_loss / num_batches\n",
        "\n",
        "    # Log average epoch losses\n",
        "    wandb.log({\"generator_loss_per_epoch\": avg_epoch_generator_loss, \"discriminator_loss_per_epoch\": avg_epoch_discriminator_loss}, step=current_epoch)\n",
        "\n",
        "# Finish Weights & Biases run\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-14T01:10:22.538539Z",
          "iopub.execute_input": "2024-04-14T01:10:22.538905Z",
          "iopub.status.idle": "2024-04-14T03:08:04.801247Z",
          "shell.execute_reply.started": "2024-04-14T01:10:22.538876Z",
          "shell.execute_reply": "2024-04-14T03:08:04.800437Z"
        },
        "trusted": true,
        "id": "nbS4PyE40GHH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(generator.state_dict(), 'generator.pth')"
      ],
      "metadata": {
        "id": "xRln9Sf_3BVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}